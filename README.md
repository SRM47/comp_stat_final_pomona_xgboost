Exploration into **XGBoost**

During the Fall 2022 Semester, I took MATH154 Computational Statistics at Pomona College which was a wide survey into the theory behind many popular machine learning and statistical methods. For my final project, I decided to explore deeper into one of the methods we learned, Gradient Boosted Trees, and write a final paper about XGBoost for regression and how it compares to other regression techniques such as Support Vector Regression, Gaussian Process Regression, LASSO Regression, and Random Forest Regression.

Above is the code and the paper associated with the Final Project. 
